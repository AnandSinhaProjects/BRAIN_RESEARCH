{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pydicom","metadata":{"id":"dvoy4P_xzHIl","outputId":"77afd2d5-5fb1-4584-b8ad-a844ff0bf3ce","execution":{"iopub.status.busy":"2021-09-10T12:18:03.956543Z","iopub.execute_input":"2021-09-10T12:18:03.957169Z","iopub.status.idle":"2021-09-10T12:18:11.132369Z","shell.execute_reply.started":"2021-09-10T12:18:03.957094Z","shell.execute_reply":"2021-09-10T12:18:11.131363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport pydicom\nimport numpy as np\nimport shutil\nfrom PIL import Image\nimport scipy\nimport torch \nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models , datasets\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\nimport copy\n\nprint(\"Done!\")","metadata":{"id":"RDqim7AetxX2","outputId":"371b2941-0e95-4df5-9a6f-0c24df820011","execution":{"iopub.status.busy":"2021-09-10T12:18:11.139628Z","iopub.execute_input":"2021-09-10T12:18:11.139979Z","iopub.status.idle":"2021-09-10T12:18:12.851883Z","shell.execute_reply.started":"2021-09-10T12:18:11.139949Z","shell.execute_reply":"2021-09-10T12:18:12.850953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -p kaggle","metadata":{"id":"NqFzQ4LbzIoK","outputId":"0bfe8d8b-dfed-4b32-882e-c7b2e403d804","execution":{"iopub.status.busy":"2021-09-10T12:18:12.853522Z","iopub.execute_input":"2021-09-10T12:18:12.854075Z","iopub.status.idle":"2021-09-10T12:18:14.138005Z","shell.execute_reply.started":"2021-09-10T12:18:12.85403Z","shell.execute_reply":"2021-09-10T12:18:14.137077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! ls '../input/png-dataset-for-rsna-mgmt-detection/png_data/png_voxel_converted_ds/train'","metadata":{"id":"xzay4E300wjQ","outputId":"ceb68b20-a01b-466c-d627-cb7a279d049e","execution":{"iopub.status.busy":"2021-09-10T12:18:14.141196Z","iopub.execute_input":"2021-09-10T12:18:14.141471Z","iopub.status.idle":"2021-09-10T12:18:14.857437Z","shell.execute_reply.started":"2021-09-10T12:18:14.141442Z","shell.execute_reply":"2021-09-10T12:18:14.856517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir \"data\"\n!mkdir \"data/0\"\n!mkdir \"data/1\"\nlabels = pd.read_csv(\"../input/png-dataset-for-rsna-mgmt-detection/png_data/png_voxel_converted_ds/train_labels.csv\")","metadata":{"id":"zFXBI9AB1N1n","execution":{"iopub.status.busy":"2021-09-10T12:18:14.860552Z","iopub.execute_input":"2021-09-10T12:18:14.860843Z","iopub.status.idle":"2021-09-10T12:18:16.787643Z","shell.execute_reply.started":"2021-09-10T12:18:14.860814Z","shell.execute_reply":"2021-09-10T12:18:16.786688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_folder_path = \"../input/png-dataset-for-rsna-mgmt-detection/png_data/png_voxel_converted_ds\"","metadata":{"id":"d3o5Ca1S1qUd","execution":{"iopub.status.busy":"2021-09-10T12:18:16.789045Z","iopub.execute_input":"2021-09-10T12:18:16.78939Z","iopub.status.idle":"2021-09-10T12:18:16.796665Z","shell.execute_reply.started":"2021-09-10T12:18:16.78935Z","shell.execute_reply":"2021-09-10T12:18:16.795782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_train_folder_path = os.path.join(main_folder_path, \"train\")\nfor subject in tqdm(os.listdir(main_train_folder_path)):\n  subject_folder = os.path.join(main_train_folder_path , subject)\n  for mri_type in os.listdir(subject_folder):\n    mri_type_folder = os.path.join(subject_folder, mri_type)\n    for mri_image in os.listdir(mri_type_folder):\n      orignal_image_path = os.path.join(mri_type_folder, mri_image)\n      mri_image = subject + \"_\" + mri_type + \"_\" + mri_image\n      subject_num = int(subject)\n      idx=np.where(labels['BraTS21ID']== subject_num)[0][0]\n      label = str(labels.loc[idx, 'MGMT_value'])\n      new_image_folder_path = os.path.join(\"data\", label)\n      new_image_path = os.path.join(new_image_folder_path, mri_image)\n      shutil.copy(orignal_image_path, new_image_path)","metadata":{"id":"Zo2_gMiT1x7G","outputId":"32736283-2e81-4801-eb17-37e28a0c3eb9","execution":{"iopub.status.busy":"2021-09-10T12:18:16.798079Z","iopub.execute_input":"2021-09-10T12:18:16.79849Z","iopub.status.idle":"2021-09-10T12:18:30.774362Z","shell.execute_reply.started":"2021-09-10T12:18:16.798457Z","shell.execute_reply":"2021-09-10T12:18:30.771337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Images with label 0 = \" , len(os.listdir(\"data/0\")) , \"Images with label 1 = \" , len(os.listdir(\"data/1\")))","metadata":{"id":"oKq_2MAx5hnP","outputId":"b6876b46-2289-4601-ecbd-7ca01f4d5936","execution":{"iopub.status.busy":"2021-09-10T12:18:30.775136Z","iopub.status.idle":"2021-09-10T12:18:30.775501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for folder in os.listdir(\"data\"):\n    folder_name = str(folder)\n    path = \"data/\"+folder_name\n    for file in tqdm(os.listdir(path)):\n        img = Image.open(path + '/' + file)\n        clrs = img.getcolors()\n        if len(clrs) == 1:\n            os.remove(path + '/' + file)","metadata":{"id":"R0Yzm4Wb53Ef","outputId":"0e93dd1b-db07-43fa-aa02-387b3d9ac40c","execution":{"iopub.status.busy":"2021-09-10T12:18:30.780056Z","iopub.status.idle":"2021-09-10T12:18:30.780463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Images with label 0 = \" , len(os.listdir(\"data/0\")) , \"Images with label 1 = \" , len(os.listdir(\"data/1\")))","metadata":{"id":"2KExpU-19ILp","outputId":"bceb851c-2ef7-4947-d45c-bd820093c64e","execution":{"iopub.status.busy":"2021-09-10T12:18:30.783817Z","iopub.status.idle":"2021-09-10T12:18:30.784197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir \"data/TRAIN\"\n!mkdir \"data/TRAIN/1\"\n!mkdir \"data/TRAIN/0\"\n!mkdir \"data/VAL\"\n!mkdir \"data/VAL/0\"\n!mkdir \"data/VAL/1\"\n!mkdir \"data/TEST\"\n!mkdir \"data/TEST/0\"\n!mkdir \"data/TEST/1\"","metadata":{"id":"uc0vIaOT9wEv","execution":{"iopub.status.busy":"2021-09-10T12:18:30.787531Z","iopub.status.idle":"2021-09-10T12:18:30.787922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_PATH = \"./data\"\n\nfor CLASS in tqdm([\"0\", \"1\"]):\n  IMG_NUM = len(os.listdir(IMG_PATH + \"/\" + CLASS))\n  for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + '/' + CLASS)):\n    img = IMG_PATH+ '/' + CLASS + '/' + FILE_NAME\n    if n<4000 :\n      shutil.copy(img, 'data/TEST/' + str(CLASS) + '/' + FILE_NAME)\n    elif n<0.9*IMG_NUM:\n      shutil.copy(img, 'data/TRAIN/' + str(CLASS) + '/' + FILE_NAME)\n    else:\n      shutil.copy(img, 'data/VAL/' + str(CLASS) + '/' + FILE_NAME)\n","metadata":{"id":"umnVUEeH9z2h","outputId":"c57c3eb6-565e-48a8-eca7-a1ba32806ce5","execution":{"iopub.status.busy":"2021-09-10T12:18:30.788924Z","iopub.status.idle":"2021-09-10T12:18:30.789495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf \"data/0\"\n!rm -rf \"data/1\"","metadata":{"id":"qWpA4bFu_zXF","execution":{"iopub.status.busy":"2021-09-10T12:18:30.790743Z","iopub.status.idle":"2021-09-10T12:18:30.791297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(\"data/TRAIN/1\")) , len(os.listdir(\"data/TRAIN/0\")) , len(os.listdir(\"data/VAL/1\")) , len(os.listdir(\"data/VAL/0\")) , len(os.listdir(\"data/TEST/1\")) , len(os.listdir(\"data/TEST/0\"))","metadata":{"id":"QAnxxaB9AJYv","outputId":"cf3391b1-da68-4637-d7e7-2dd11a5631e3","execution":{"iopub.status.busy":"2021-09-10T12:18:30.79231Z","iopub.status.idle":"2021-09-10T12:18:30.792877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'TRAIN' : transforms.Compose([\n                                  transforms.RandomResizedCrop(224),\n                                  transforms.RandomHorizontalFlip(),\n                                  transforms.ToTensor(),\n                                  transforms.Normalize(mean, std)\n    ]),\n\n    'VAL' : transforms.Compose([\n                               transforms.Resize(256),\n                               transforms.CenterCrop(224),\n                               transforms.ToTensor(),\n                               transforms.Normalize(mean, std)\n    ]),\n\n    'TEST' : transforms.Compose([\n                                 transforms.Resize(256),\n                                 transforms.CenterCrop(224),\n                                 transforms.ToTensor(),\n                                 transforms.Normalize(mean, std)\n    ]),\n}","metadata":{"id":"IFVJV9p_AM3K","execution":{"iopub.status.busy":"2021-09-10T12:18:30.794081Z","iopub.status.idle":"2021-09-10T12:18:30.794645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = 'data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['TRAIN', 'VAL' , 'TEST']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=0)\n              for x in ['TRAIN', 'VAL' , 'TEST']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['TRAIN', 'VAL' , 'TEST']}\nclass_names = image_datasets['TRAIN'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(class_names)","metadata":{"id":"YhlkpgOBCMvr","outputId":"741fa38e-1172-400f-c425-c0f1934a0ba3","execution":{"iopub.status.busy":"2021-09-10T12:18:30.795767Z","iopub.status.idle":"2021-09-10T12:18:30.796324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ndef imshow(inp, title):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    plt.title(title)\n    plt.show()","metadata":{"id":"U1ZM0PMYCfDS","execution":{"iopub.status.busy":"2021-09-10T12:18:30.797446Z","iopub.status.idle":"2021-09-10T12:18:30.798025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['TRAIN']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","metadata":{"id":"0OFAkvEEDN7S","outputId":"da0e25af-fd50-4f3b-81db-6edef48624f0","execution":{"iopub.status.busy":"2021-09-10T12:18:30.79905Z","iopub.status.idle":"2021-09-10T12:18:30.799612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, model_name, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['TRAIN' , 'VAL']:\n            if phase == 'TRAIN':\n                model.train()  # Set model to training mode\n            elif phase == 'VAL':\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'TRAIN'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'TRAIN':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'TRAIN':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'VAL' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                #save the best model\n                torch.save(model , model_name+'weights.pt')\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))","metadata":{"id":"gxUKspYIDSVr","execution":{"iopub.status.busy":"2021-09-10T12:18:30.800899Z","iopub.status.idle":"2021-09-10T12:18:30.801447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"SZnNCwDxqZ3k","outputId":"e07b5269-2483-4e64-f57d-8b8c944756a9","execution":{"iopub.status.busy":"2021-09-10T12:18:30.802522Z","iopub.status.idle":"2021-09-10T12:18:30.803096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnext101 = models.resnext101_32x8d(pretrained=True)\nnum_ftrs = resnext101.fc.in_features","metadata":{"id":"xoE8DqHXLjkF","execution":{"iopub.status.busy":"2021-09-10T12:18:30.804277Z","iopub.status.idle":"2021-09-10T12:18:30.804863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnext101.fc = nn.Linear(num_ftrs, 2)\n\nresnext101 = resnext101.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(resnext101.parameters(), lr=0.001)","metadata":{"id":"2osLbwmjNY7H","execution":{"iopub.status.busy":"2021-09-10T12:18:30.805979Z","iopub.status.idle":"2021-09-10T12:18:30.806529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ntrain_model(resnext101,\"resnext101\", criterion, optimizer, step_lr_scheduler, num_epochs=20)","metadata":{"id":"y2Pw5qDpNaoP","execution":{"iopub.status.busy":"2021-09-10T12:18:30.807764Z","iopub.status.idle":"2021-09-10T12:18:30.808319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wide_resnet101 = models.wide_resnet101_2(pretrained=True)\n# num_ftrs = wide_resnet101.classifier[6].in_features","metadata":{"id":"JdwjS2TSOb44","execution":{"iopub.status.busy":"2021-09-10T12:18:30.809513Z","iopub.status.idle":"2021-09-10T12:18:30.810126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wide_resnet101.classifier[6] = nn.Linear(num_ftrs,2)\n\n# wide_resnet101 = wide_resnet101.to(device)\n\n# criterion = nn.CrossEntropyLoss()\n\n# optimizer = optim.SGD(wide_resnet101.parameters, lr=0.001)","metadata":{"id":"ehtUCKbrOfVl","execution":{"iopub.status.busy":"2021-09-10T12:18:30.811357Z","iopub.status.idle":"2021-09-10T12:18:30.812034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n# train_model(wide_resnext101,\"wide_resnext101\", criterion, optimizer, step_lr_scheduler, num_epochs=20)","metadata":{"id":"ce1GK9qiOhJN","execution":{"iopub.status.busy":"2021-09-10T12:18:30.813291Z","iopub.status.idle":"2021-09-10T12:18:30.813877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! nvidia-smi","metadata":{"id":"adl_XD7akZZJ","outputId":"4bb50439-56ad-4462-f010-d6aece6bbfc8","execution":{"iopub.status.busy":"2021-09-10T12:18:30.815103Z","iopub.status.idle":"2021-09-10T12:18:30.815751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,10))\nplt.title(\"Train-Validation Accuracy\")\nplt.plot(train_acc, label='train')\nplt.plot(val_acc, label='validation')\nplt.xlabel('num_epochs', fontsize=12)\nplt.ylabel('accuracy', fontsize=12)\nplt.legend(loc='best')","metadata":{"id":"4po6cw62oY9G","execution":{"iopub.status.busy":"2021-09-10T12:18:30.816994Z","iopub.status.idle":"2021-09-10T12:18:30.817532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}